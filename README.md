# ğŸ›ï¸ Volume Control Using Hand Gestures

A computer vision project that allows users to control their system volume using simple hand gestures â€” completely touch-free. This is achieved using a webcam, MediaPipe for hand tracking, OpenCV for visualization, and Pycaw to control the system audio.

## ğŸ“¸ How It Works

- The webcam captures real-time video.
- MediaPipe detects and tracks hand landmarks.
- The distance between the **thumb tip** and **index finger tip** is calculated.
- This distance is mapped to a volume range using the `pycaw` audio library.
- Visual feedback (volume bar, percentage, and FPS) is displayed using OpenCV.

## âœ¨ Features

- Real-time hand tracking using MediaPipe
- Smooth volume control with natural gestures
- Visual volume bar and percentage overlay
- FPS counter to monitor performance
- Touchless user interface ideal for smart environments and accessibility

## ğŸ› ï¸ Tech Stack

- **Python**
- **OpenCV** â€“ for capturing and displaying video
- **MediaPipe** â€“ for hand landmark detection
- **Pycaw** â€“ for controlling system volume
- **NumPy** and **Math** â€“ for interpolation and distance calculation

## Project Structure

â”œâ”€â”€ HandTrackingModule.py       # Hand detection class using MediaPipe

â”œâ”€â”€ VolumeHandControl.py        # Main script for volume control

â””â”€â”€ README.md                   # Project documentation

## ğŸ§° Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/Maheswara23/volume-control-hand-gesture.git
   cd volume-control-hand-gesture

2. Install   required libraries:
   ```bash
   pip install opencv-python mediapipe pycaw comtypes numpy

3. Run the Project
   ```bash
   python VolumeHandControl.py
